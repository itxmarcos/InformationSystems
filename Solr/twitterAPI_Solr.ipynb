{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import * #urlib2 has been moved to several modules\n",
    "import tweepy\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {}\n",
    "credentials['api_key'] = 'n2dTtVbZuJwji0auruBGVTBwT'\n",
    "credentials['api_secret_key'] = 'U1Er7hNUFtOwmPIz6BCr6w1B3o9GlKhg6loffJVIK0cFAFdkYl'\n",
    "credentials['access_token'] = '987093510116532231-tiHjc16Ws3vcMZpNUt0kuL7xj8iLSy1'\n",
    "credentials['access_token_secret'] = 'ykZmkTz2TIeSajyWDKXvSSxAiFZvMFdD9ePUe0zn5fsna'\n",
    "\n",
    "# Save the credentials object to file\n",
    "with open(\"twitter_credentials.json\", \"w\") as file:\n",
    "    json.dump(credentials, file)\n",
    "\n",
    "# Load Twitter API secrets from an external JSON file\n",
    "api_key = credentials['api_key']\n",
    "api_secret_key = credentials['api_secret_key']\n",
    "access_token = credentials['access_token']\n",
    "access_token_secret = credentials['access_token_secret']\n",
    "\n",
    "# Twitter initialization\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "    # initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "    \n",
    "    # make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "    \n",
    "    # save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    # save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    # keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(\"getting tweets before %s\" % (oldest))\n",
    "        \n",
    "        # all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "        \n",
    "        # save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        # update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "        \n",
    "    #Write into Solr\n",
    "    myUser = {\n",
    "        'id_str' : alltweets[0].user.id_str,\n",
    "        'screen_name' : alltweets[0].user.screen_name,\n",
    "        'followers_count' : alltweets[0].user.followers_count,\n",
    "        'friends_count' : alltweets[0].user.friends_count\n",
    "    }\n",
    "    json_str_usr = json.dumps(myUser)\n",
    "    \n",
    "    for tweet in alltweets:\n",
    "        myTweet = {\n",
    "            'id_str' : tweet.id_str,\n",
    "            'user_id_str' : tweet.user.id_str,\n",
    "            'created_at' : str(tweet.created_at),\n",
    "            'text' : tweet.text,\n",
    "            'favorite_count' : tweet.favorite_count,\n",
    "            'in_reply_to_screen_name' : tweet.in_reply_to_screen_name,\n",
    "            'retweeted' : tweet.retweeted\n",
    "        }\n",
    "        json_str_twt = json.dumps(myTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'responseHeader': {'rf': 2, 'status': 0, 'QTime': 88}}\n",
      "{'responseHeader': {'status': 0, 'QTime': 494}}\n"
     ]
    }
   ],
   "source": [
    "#Metodo GET\n",
    "payload = {'username':'olivia','password':'123'}\n",
    "url='http://localhost:8983/solr/Tweets/update/json/docs'\n",
    "headers = {'content-type': 'application/json'}\n",
    "r = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "print(r.json())\n",
    "\n",
    "#Metodo POST\n",
    "url='http://localhost:8983/solr/Tweets/update/json?commit=true%27'\n",
    "r = requests.get(url)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 987094350722191359\n",
      "...108 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    get_all_tweets(\"srcaballero99\") #pass in the username of the account you want to insert\n",
    "    #get_all_tweets(\"Star_Lord987\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
